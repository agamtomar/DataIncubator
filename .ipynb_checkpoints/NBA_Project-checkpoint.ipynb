{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# R-code for loading and saving the hormone database in .csv format\\nlibrary(\"bootstrap\")\\nwrite.csv(hormone, \\'hormone.csv\\')\\n'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# R-code for loading and saving the hormone database in .csv format\n",
    "library(\"bootstrap\")\n",
    "write.csv(hormone, 'hormone.csv')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the hormone dataset Page 107 : Efron Book\n",
    "hormone_data = pd.read_csv('hormone.csv', delimiter=',', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lot</th>\n",
       "      <th>hrs</th>\n",
       "      <th>amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A</td>\n",
       "      <td>99</td>\n",
       "      <td>25.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A</td>\n",
       "      <td>152</td>\n",
       "      <td>20.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A</td>\n",
       "      <td>293</td>\n",
       "      <td>14.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A</td>\n",
       "      <td>155</td>\n",
       "      <td>23.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>A</td>\n",
       "      <td>196</td>\n",
       "      <td>20.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>A</td>\n",
       "      <td>53</td>\n",
       "      <td>31.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>A</td>\n",
       "      <td>184</td>\n",
       "      <td>20.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>A</td>\n",
       "      <td>171</td>\n",
       "      <td>20.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>A</td>\n",
       "      <td>52</td>\n",
       "      <td>30.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>B</td>\n",
       "      <td>376</td>\n",
       "      <td>16.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>B</td>\n",
       "      <td>385</td>\n",
       "      <td>11.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>B</td>\n",
       "      <td>402</td>\n",
       "      <td>11.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>B</td>\n",
       "      <td>29</td>\n",
       "      <td>32.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>B</td>\n",
       "      <td>76</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>B</td>\n",
       "      <td>296</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>B</td>\n",
       "      <td>151</td>\n",
       "      <td>24.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>B</td>\n",
       "      <td>177</td>\n",
       "      <td>26.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>B</td>\n",
       "      <td>209</td>\n",
       "      <td>25.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>C</td>\n",
       "      <td>119</td>\n",
       "      <td>28.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>C</td>\n",
       "      <td>188</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>C</td>\n",
       "      <td>115</td>\n",
       "      <td>29.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>C</td>\n",
       "      <td>88</td>\n",
       "      <td>28.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>C</td>\n",
       "      <td>58</td>\n",
       "      <td>32.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>C</td>\n",
       "      <td>49</td>\n",
       "      <td>32.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>C</td>\n",
       "      <td>150</td>\n",
       "      <td>25.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>C</td>\n",
       "      <td>107</td>\n",
       "      <td>31.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>C</td>\n",
       "      <td>125</td>\n",
       "      <td>28.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Lot  hrs  amount\n",
       "1    A   99    25.8\n",
       "2    A  152    20.5\n",
       "3    A  293    14.3\n",
       "4    A  155    23.2\n",
       "5    A  196    20.6\n",
       "6    A   53    31.1\n",
       "7    A  184    20.9\n",
       "8    A  171    20.9\n",
       "9    A   52    30.4\n",
       "10   B  376    16.3\n",
       "11   B  385    11.6\n",
       "12   B  402    11.8\n",
       "13   B   29    32.5\n",
       "14   B   76    32.0\n",
       "15   B  296    18.0\n",
       "16   B  151    24.1\n",
       "17   B  177    26.5\n",
       "18   B  209    25.8\n",
       "19   C  119    28.8\n",
       "20   C  188    22.0\n",
       "21   C  115    29.7\n",
       "22   C   88    28.9\n",
       "23   C   58    32.8\n",
       "24   C   49    32.5\n",
       "25   C  150    25.4\n",
       "26   C  107    31.7\n",
       "27   C  125    28.5"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hormone_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'amount')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Figure 9.1\n",
    "plt.figure()\n",
    "plt.scatter(hormone_data[hormone_data['Lot'] == 'A']['hrs'], hormone_data[hormone_data['Lot'] == 'A']['amount'], c='r')\n",
    "plt.scatter(hormone_data[hormone_data['Lot'] == 'B']['hrs'], hormone_data[hormone_data['Lot'] == 'B']['amount'], c='g')\n",
    "plt.scatter(hormone_data[hormone_data['Lot'] == 'C']['hrs'], hormone_data[hormone_data['Lot'] == 'C']['amount'], c='b')\n",
    "plt.legend(['A', 'B', 'C'])\n",
    "plt.xlabel('Hours')\n",
    "plt.ylabel('amount')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 17.8 \n",
    "(a) Carry out a bootstrap analysis for the hormone data,\n",
    "like the one in Table 17.1, using B = 100 bootstrap samples.\n",
    "In addition, calculate the average prediction error €0 for observations that do not appear in the bootstrap\n",
    "sample used for their prediction. Hence compute the .632\n",
    "estimator for these data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "len_data = len(hormone_data)\n",
    "X_lotA = np.array(hormone_data[hormone_data['Lot'] == 'A']['hrs']).reshape(-1,1)\n",
    "X_lotB = np.array(hormone_data[hormone_data['Lot'] == 'B']['hrs']).reshape(-1,1)\n",
    "X_lotC = np.array(hormone_data[hormone_data['Lot'] == 'C']['hrs']).reshape(-1,1)\n",
    "\n",
    "y_lotA = np.array(hormone_data[hormone_data['Lot'] == 'A']['amount']).reshape(-1,1)\n",
    "y_lotB = np.array(hormone_data[hormone_data['Lot'] == 'B']['amount']).reshape(-1,1)\n",
    "y_lotC = np.array(hormone_data[hormone_data['Lot'] == 'C']['amount']).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction Error after training on Hormone dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "X = np.zeros((27, 4))\n",
    "\n",
    "X[:,0] = np.array(hormone_data['hrs'], dtype=np.float)\n",
    "X[0:9, 1] = np.ones((9))\n",
    "X[9:18,2] = np.ones((9))\n",
    "X[18:27,3] = np.ones((9))\n",
    "\n",
    "y = np.array(hormone_data['amount']).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.1952182295633147"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regr = LinearRegression(fit_intercept=False)\n",
    "\n",
    "regr.fit(X, y)\n",
    "RSE = mean_squared_error(y, regr.predict(X))\n",
    "RSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction Error: 2.195218\n"
     ]
    }
   ],
   "source": [
    "print(\"Prediction Error: %f\" % RSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bootstrap Estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "B = 400\n",
    "NaiveBSResults_df = pd.DataFrame(index=np.arange(B), columns=['Prediction Error', 'Apparent Error', 'Optimism'], dtype=np.float)\n",
    "NaiveBS_df = pd.DataFrame(index=np.arange(1, len_data+1), columns=np.arange(B))\n",
    "\n",
    "for rep in range(B):\n",
    "\n",
    "    b_idxs = np.random.choice(a=np.arange(1, len_data+1), size=len_data, replace=True)\n",
    "    NaiveBS_df.loc[:, rep] = b_idxs\n",
    "    b_data = hormone_data.loc[b_idxs]\n",
    "\n",
    "    # Fitting each lot\n",
    "    PE_original = 0\n",
    "    PE_boot = 0\n",
    "\n",
    "    X_boot = np.zeros((27,4))\n",
    "    X_boot[:, 0] = np.array(b_data['hrs'], dtype=np.float)\n",
    "\n",
    "    y_boot = np.array(b_data['amount'], dtype=np.float)\n",
    "\n",
    "    lot_data = list(b_data['Lot'])\n",
    "\n",
    "    for idx in range(len(lot_data)):\n",
    "        if lot_data[idx] == 'A':\n",
    "            X_boot[idx, 1] = 1\n",
    "        elif lot_data[idx] == 'B':\n",
    "            X_boot[idx, 2] = 1\n",
    "        elif lot_data[idx] == 'C':\n",
    "            X_boot[idx, 3] = 1\n",
    "\n",
    "    regr = LinearRegression(fit_intercept=False)\n",
    "    regr.fit(X_boot, y_boot)\n",
    "\n",
    "    y_pred = regr.predict(X)\n",
    "    y_pred_boot = regr.predict(X_boot)\n",
    "\n",
    "    PE_original = mean_squared_error(y_true=y, y_pred=y_pred)\n",
    "    PE_boot = mean_squared_error(y_true=y_boot, y_pred=y_pred_boot)\n",
    "\n",
    "    NaiveBSResults_df.loc[rep, 'Prediction Error'] = PE_original\n",
    "    NaiveBSResults_df.loc[rep, 'Apparent Error'] = PE_boot\n",
    "    NaiveBSResults_df.loc[rep, 'Optimism'] = PE_original - PE_boot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prediction Error</th>\n",
       "      <th>Apparent Error</th>\n",
       "      <th>Optimism</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.558013</td>\n",
       "      <td>1.237784</td>\n",
       "      <td>1.320229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.295050</td>\n",
       "      <td>1.615614</td>\n",
       "      <td>0.679436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.711770</td>\n",
       "      <td>2.033064</td>\n",
       "      <td>0.678706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.604423</td>\n",
       "      <td>2.084908</td>\n",
       "      <td>0.519515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.764573</td>\n",
       "      <td>1.077702</td>\n",
       "      <td>1.686871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.336437</td>\n",
       "      <td>0.728864</td>\n",
       "      <td>1.607573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2.424809</td>\n",
       "      <td>1.931757</td>\n",
       "      <td>0.493052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.264300</td>\n",
       "      <td>1.585722</td>\n",
       "      <td>0.678578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2.823836</td>\n",
       "      <td>1.293975</td>\n",
       "      <td>1.529862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2.731266</td>\n",
       "      <td>2.010310</td>\n",
       "      <td>0.720956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2.649381</td>\n",
       "      <td>2.049094</td>\n",
       "      <td>0.600287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3.567244</td>\n",
       "      <td>1.756596</td>\n",
       "      <td>1.810649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2.940591</td>\n",
       "      <td>1.717734</td>\n",
       "      <td>1.222857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2.720257</td>\n",
       "      <td>1.713162</td>\n",
       "      <td>1.007096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2.318832</td>\n",
       "      <td>0.958755</td>\n",
       "      <td>1.360077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2.632218</td>\n",
       "      <td>2.364754</td>\n",
       "      <td>0.267464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2.658831</td>\n",
       "      <td>2.138693</td>\n",
       "      <td>0.520138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2.279626</td>\n",
       "      <td>2.269688</td>\n",
       "      <td>0.009938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2.712521</td>\n",
       "      <td>1.937644</td>\n",
       "      <td>0.774877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2.631399</td>\n",
       "      <td>1.761830</td>\n",
       "      <td>0.869569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>3.626148</td>\n",
       "      <td>2.034037</td>\n",
       "      <td>1.592111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2.469423</td>\n",
       "      <td>1.691225</td>\n",
       "      <td>0.778198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2.869342</td>\n",
       "      <td>1.874580</td>\n",
       "      <td>0.994762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2.333729</td>\n",
       "      <td>1.299290</td>\n",
       "      <td>1.034439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2.548977</td>\n",
       "      <td>1.675325</td>\n",
       "      <td>0.873651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2.683754</td>\n",
       "      <td>1.843256</td>\n",
       "      <td>0.840498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2.493428</td>\n",
       "      <td>2.407372</td>\n",
       "      <td>0.086056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2.297504</td>\n",
       "      <td>1.967118</td>\n",
       "      <td>0.330386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2.430647</td>\n",
       "      <td>1.765758</td>\n",
       "      <td>0.664889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2.465316</td>\n",
       "      <td>2.339460</td>\n",
       "      <td>0.125856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>2.269351</td>\n",
       "      <td>1.839772</td>\n",
       "      <td>0.429579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>2.585629</td>\n",
       "      <td>2.812355</td>\n",
       "      <td>-0.226726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>2.519148</td>\n",
       "      <td>1.972490</td>\n",
       "      <td>0.546658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>2.278443</td>\n",
       "      <td>1.333384</td>\n",
       "      <td>0.945059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>2.645510</td>\n",
       "      <td>2.115376</td>\n",
       "      <td>0.530134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>2.733778</td>\n",
       "      <td>1.278651</td>\n",
       "      <td>1.455127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>2.630493</td>\n",
       "      <td>2.064736</td>\n",
       "      <td>0.565757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>3.600980</td>\n",
       "      <td>2.122407</td>\n",
       "      <td>1.478574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>2.355322</td>\n",
       "      <td>1.137381</td>\n",
       "      <td>1.217942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>2.338581</td>\n",
       "      <td>2.874156</td>\n",
       "      <td>-0.535575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>2.663133</td>\n",
       "      <td>2.210561</td>\n",
       "      <td>0.452571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>2.704365</td>\n",
       "      <td>2.042265</td>\n",
       "      <td>0.662100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>2.269668</td>\n",
       "      <td>2.269576</td>\n",
       "      <td>0.000092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>4.650086</td>\n",
       "      <td>1.232705</td>\n",
       "      <td>3.417381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>2.489769</td>\n",
       "      <td>1.493352</td>\n",
       "      <td>0.996417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>2.224082</td>\n",
       "      <td>1.742451</td>\n",
       "      <td>0.481630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>2.311469</td>\n",
       "      <td>1.696091</td>\n",
       "      <td>0.615377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>4.129324</td>\n",
       "      <td>1.253531</td>\n",
       "      <td>2.875792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>3.209058</td>\n",
       "      <td>1.377293</td>\n",
       "      <td>1.831765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>2.222089</td>\n",
       "      <td>2.795300</td>\n",
       "      <td>-0.573212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>2.310946</td>\n",
       "      <td>2.458244</td>\n",
       "      <td>-0.147298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>2.439417</td>\n",
       "      <td>2.348453</td>\n",
       "      <td>0.090964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>2.375438</td>\n",
       "      <td>1.513634</td>\n",
       "      <td>0.861804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>2.971514</td>\n",
       "      <td>1.257283</td>\n",
       "      <td>1.714231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>2.893966</td>\n",
       "      <td>1.365571</td>\n",
       "      <td>1.528396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>2.435453</td>\n",
       "      <td>2.074818</td>\n",
       "      <td>0.360635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>2.458607</td>\n",
       "      <td>1.216289</td>\n",
       "      <td>1.242318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>2.899266</td>\n",
       "      <td>1.709204</td>\n",
       "      <td>1.190062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>2.366574</td>\n",
       "      <td>1.740729</td>\n",
       "      <td>0.625845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>2.411124</td>\n",
       "      <td>1.646855</td>\n",
       "      <td>0.764269</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Prediction Error  Apparent Error  Optimism\n",
       "0            2.558013        1.237784  1.320229\n",
       "1            2.295050        1.615614  0.679436\n",
       "2            2.711770        2.033064  0.678706\n",
       "3            2.604423        2.084908  0.519515\n",
       "4            2.764573        1.077702  1.686871\n",
       "5            2.336437        0.728864  1.607573\n",
       "6            2.424809        1.931757  0.493052\n",
       "7            2.264300        1.585722  0.678578\n",
       "8            2.823836        1.293975  1.529862\n",
       "9            2.731266        2.010310  0.720956\n",
       "10           2.649381        2.049094  0.600287\n",
       "11           3.567244        1.756596  1.810649\n",
       "12           2.940591        1.717734  1.222857\n",
       "13           2.720257        1.713162  1.007096\n",
       "14           2.318832        0.958755  1.360077\n",
       "15           2.632218        2.364754  0.267464\n",
       "16           2.658831        2.138693  0.520138\n",
       "17           2.279626        2.269688  0.009938\n",
       "18           2.712521        1.937644  0.774877\n",
       "19           2.631399        1.761830  0.869569\n",
       "20           3.626148        2.034037  1.592111\n",
       "21           2.469423        1.691225  0.778198\n",
       "22           2.869342        1.874580  0.994762\n",
       "23           2.333729        1.299290  1.034439\n",
       "24           2.548977        1.675325  0.873651\n",
       "25           2.683754        1.843256  0.840498\n",
       "26           2.493428        2.407372  0.086056\n",
       "27           2.297504        1.967118  0.330386\n",
       "28           2.430647        1.765758  0.664889\n",
       "29           2.465316        2.339460  0.125856\n",
       "..                ...             ...       ...\n",
       "370          2.269351        1.839772  0.429579\n",
       "371          2.585629        2.812355 -0.226726\n",
       "372          2.519148        1.972490  0.546658\n",
       "373          2.278443        1.333384  0.945059\n",
       "374          2.645510        2.115376  0.530134\n",
       "375          2.733778        1.278651  1.455127\n",
       "376          2.630493        2.064736  0.565757\n",
       "377          3.600980        2.122407  1.478574\n",
       "378          2.355322        1.137381  1.217942\n",
       "379          2.338581        2.874156 -0.535575\n",
       "380          2.663133        2.210561  0.452571\n",
       "381          2.704365        2.042265  0.662100\n",
       "382          2.269668        2.269576  0.000092\n",
       "383          4.650086        1.232705  3.417381\n",
       "384          2.489769        1.493352  0.996417\n",
       "385          2.224082        1.742451  0.481630\n",
       "386          2.311469        1.696091  0.615377\n",
       "387          4.129324        1.253531  2.875792\n",
       "388          3.209058        1.377293  1.831765\n",
       "389          2.222089        2.795300 -0.573212\n",
       "390          2.310946        2.458244 -0.147298\n",
       "391          2.439417        2.348453  0.090964\n",
       "392          2.375438        1.513634  0.861804\n",
       "393          2.971514        1.257283  1.714231\n",
       "394          2.893966        1.365571  1.528396\n",
       "395          2.435453        2.074818  0.360635\n",
       "396          2.458607        1.216289  1.242318\n",
       "397          2.899266        1.709204  1.190062\n",
       "398          2.366574        1.740729  0.625845\n",
       "399          2.411124        1.646855  0.764269\n",
       "\n",
       "[400 rows x 3 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NaiveBSResults_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction Error    2.671607\n",
       "Apparent Error      1.826374\n",
       "Optimism            0.845233\n",
       "dtype: float64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NaiveBSResults_df.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrap Estimate of Prediction Error: 2.671607\n"
     ]
    }
   ],
   "source": [
    "print(\"Bootstrap Estimate of Prediction Error: %f\" % NaiveBSResults_df['Prediction Error'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Refined BootStrap Estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Refined Bootstrap estimate of prediction Error: 3.040452\n"
     ]
    }
   ],
   "source": [
    "RefinedBSEstimate = RSE + NaiveBSResults_df[\"Optimism\"].mean()\n",
    "print(\"Refined Bootstrap estimate of prediction Error: %f\" % RefinedBSEstimate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating Epsilon_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps_dict = {x:[] for x in np.arange(1, len_data+1)}\n",
    "\n",
    "for obs in np.arange(1, len_data+1):  # Looping over each observation\n",
    "    for b in range(B):  # Looping over bootstrap sample\n",
    "        if obs not in np.array(NaiveBS_df[b]): # Check if the observation appear in corresponding bootstrap sample\n",
    "            eps_dict[obs].append(b)\n",
    "\n",
    "\n",
    "eps_err = []\n",
    "for eps in eps_dict:\n",
    "\n",
    "    err = 0\n",
    "    for bs_sample_idx in eps_dict[eps]:\n",
    "\n",
    "        b_idxs = NaiveBS_df[bs_sample_idx]\n",
    "\n",
    "        b_data = hormone_data.loc[b_idxs]\n",
    "\n",
    "        X_boot = np.zeros((27, 4))\n",
    "        X_boot[:, 0] = np.array(b_data['hrs'], dtype=np.float)\n",
    "\n",
    "        y_boot = np.array(b_data['amount'], dtype=np.float)\n",
    "\n",
    "        lot_data = list(b_data['Lot'])\n",
    "\n",
    "        for idx in range(len(lot_data)):\n",
    "            if lot_data[idx] == 'A':\n",
    "                X_boot[idx, 1] = 1\n",
    "            elif lot_data[idx] == 'B':\n",
    "                X_boot[idx, 2] = 1\n",
    "            elif lot_data[idx] == 'C':\n",
    "                X_boot[idx, 3] = 1\n",
    "\n",
    "        regr = LinearRegression(fit_intercept=False)\n",
    "        regr.fit(X_boot, y_boot)\n",
    "\n",
    "        y_pred = regr.predict(X[eps-1,:].reshape(1, -1))\n",
    "\n",
    "        err += (y[eps-1] - y_pred)**2\n",
    "\n",
    "    if len(eps_dict[eps]) > 0:\n",
    "        err = err/len(eps_dict[eps])\n",
    "    eps_err.append(err)\n",
    "\n",
    "eps_0 = np.mean(eps_err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average error rate from bootstrap data sets not contatining the point being predicted: 3.770541\n"
     ]
    }
   ],
   "source": [
    "print(\"Average error rate from bootstrap data sets not contatining the point being predicted: %f\" % eps_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator_632 = (0.368 * RSE) + (0.632 * eps_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".632 estimate of prediction error: 3.190822\n"
     ]
    }
   ],
   "source": [
    "print(\".632 estimate of prediction error: %f\" % estimator_632)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction Error: 2.195218\n",
      "Bootstrap Estimate of Prediction Error: 2.671607\n",
      "Refined Bootstrap estimate of prediction Error: 3.040452\n",
      "Average error rate from bootstrap data sets not containing the point being predicted: 3.770541\n",
      ".632 estimate of prediction error: 3.190822\n"
     ]
    }
   ],
   "source": [
    "print(\"Prediction Error: %f\" % RSE)\n",
    "print(\"Bootstrap Estimate of Prediction Error: %f\" % NaiveBSResults_df['Prediction Error'].mean())\n",
    "print(\"Refined Bootstrap estimate of prediction Error: %f\" % RefinedBSEstimate)\n",
    "print(\"Average error rate from bootstrap data sets not containing the point being predicted: %f\" % eps_0)\n",
    "print(\".632 estimate of prediction error: %f\" % estimator_632)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculation epsilon0, epsilon1, ....\n",
    "epsilon_range = 27\n",
    "eps_dict_list = [{x:[] for x in np.arange(1, len_data+1)} for i in range(epsilon_range)]\n",
    "\n",
    "for i in range(epsilon_range):\n",
    "    eps_dict = eps_dict_list[i]\n",
    "\n",
    "    for obs in np.arange(1, len_data+1):  # Looping over each observation\n",
    "        for b in range(B):  # Looping over bootstrap sample\n",
    "            if i == list(NaiveBS_df[b]).count(obs): # Check if the observation appear in corresponding bootstrap sample\n",
    "                eps_dict[obs].append(b)\n",
    "\n",
    "eps_err_list = [0 for i in range(epsilon_range)]\n",
    "\n",
    "for i in range(epsilon_range):\n",
    "\n",
    "    eps_dict = eps_dict_list[i]\n",
    "\n",
    "    eps_err = []\n",
    "    for eps in eps_dict:\n",
    "\n",
    "        err = 0\n",
    "        for bs_sample_idx in eps_dict[eps]:\n",
    "\n",
    "            b_idxs = NaiveBS_df[bs_sample_idx]\n",
    "\n",
    "            b_data = hormone_data.loc[b_idxs]\n",
    "\n",
    "            X_boot = np.zeros((27, 4))\n",
    "            X_boot[:, 0] = np.array(b_data['hrs'], dtype=np.float)\n",
    "\n",
    "            y_boot = np.array(b_data['amount'], dtype=np.float)\n",
    "\n",
    "            lot_data = list(b_data['Lot'])\n",
    "\n",
    "            for idx in range(len(lot_data)):\n",
    "                if lot_data[idx] == 'A':\n",
    "                    X_boot[idx, 1] = 1\n",
    "                elif lot_data[idx] == 'B':\n",
    "                    X_boot[idx, 2] = 1\n",
    "                elif lot_data[idx] == 'C':\n",
    "                    X_boot[idx, 3] = 1\n",
    "\n",
    "            regr = LinearRegression(fit_intercept=False)\n",
    "            regr.fit(X_boot, y_boot)\n",
    "\n",
    "            y_pred = regr.predict(X[eps-1,:].reshape(1, -1))\n",
    "\n",
    "            err += (y[eps-1] - y_pred)**2\n",
    "\n",
    "        if len(eps_dict[eps]) > 0:\n",
    "            err = err/len(eps_dict[eps])\n",
    "        eps_err.append(err)\n",
    "\n",
    "    eps_err_list[i] = np.mean(eps_err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.scatter(range(epsilon_range), eps_err_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
